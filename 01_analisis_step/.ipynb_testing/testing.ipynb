{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instalando librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pyspark modules\n",
    "\n",
    "from pyspark.sql.functions import udf, lower, col, regexp_replace, concat_ws, collect_list\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from pyspark.sql.types import StructType, ArrayType, StringType\n",
    "\n",
    "#Load the librarys\n",
    "\n",
    "import seaborn as sns #Graph library that use matplot in background\n",
    "import matplotlib.pyplot as plt #to plot some parameters in seaborn\n",
    "\n",
    "\n",
    "# standard modules\n",
    "import re\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pandas as pd #To work with dataset\n",
    "import numpy as np #Math library\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas_profiling import ProfileReport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start session\n",
    "spark = SparkSession.builder.appName(\"Analysis\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#downloading data\n",
    "input_loc = '/Users/52667/Documents/Airflow-P2/00_input_data/german_credit_data.csv'\n",
    "df_credit = spark.read.option(\"header\", True).csv(input_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_credit=pd.read_csv('/Users/52667/Documents/Airflow-P2/00_input_data/german_credit_data.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1000 entries, 0 to 999\n",
      "Data columns (total 9 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   Age               1000 non-null   int64 \n",
      " 1   Sex               1000 non-null   object\n",
      " 2   Job               1000 non-null   int64 \n",
      " 3   Housing           1000 non-null   object\n",
      " 4   Saving accounts   817 non-null    object\n",
      " 5   Checking account  606 non-null    object\n",
      " 6   Credit amount     1000 non-null   int64 \n",
      " 7   Duration          1000 non-null   int64 \n",
      " 8   Purpose           1000 non-null   object\n",
      "dtypes: int64(4), object(5)\n",
      "memory usage: 78.1+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#Searching for Missings,type of data and also known the shape of data\n",
    "print(df_credit.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age                  53\n",
      "Sex                   2\n",
      "Job                   4\n",
      "Housing               3\n",
      "Saving accounts       4\n",
      "Checking account      3\n",
      "Credit amount       921\n",
      "Duration             33\n",
      "Purpose               8\n",
      "dtype: int64\n",
      "   Age     Sex  Job Housing Saving accounts Checking account  Credit amount  \\\n",
      "0   67    male    2     own             NaN           little           1169   \n",
      "1   22  female    2     own          little         moderate           5951   \n",
      "2   49    male    1     own          little              NaN           2096   \n",
      "3   45    male    2    free          little           little           7882   \n",
      "4   53    male    2    free          little           little           4870   \n",
      "\n",
      "   Duration              Purpose  \n",
      "0         6             radio/TV  \n",
      "1        48             radio/TV  \n",
      "2        12            education  \n",
      "3        42  furniture/equipment  \n",
      "4        24                  car  \n"
     ]
    }
   ],
   "source": [
    "#Looking unique values\n",
    "print(df_credit.nunique())\n",
    "#Looking the data\n",
    "print(df_credit.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile=ProfileReport(df_credit,title='Data Quality')\n",
    "profile.to_file('/Users/52667/Documents/Airflow-P2/00_input_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "foo\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.20.0.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyError",
     "evalue": "'Risk'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\indexes\\base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3801\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\_libs\\index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\_libs\\index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Risk'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 17\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mwarnings\u001b[39;00m \u001b[39m# This library will be used to ignore some warnings\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mcollections\u001b[39;00m \u001b[39mimport\u001b[39;00m Counter \u001b[39m# To do counter of some features\u001b[39;00m\n\u001b[0;32m     16\u001b[0m trace0 \u001b[39m=\u001b[39m go\u001b[39m.\u001b[39mBar(\n\u001b[1;32m---> 17\u001b[0m             x \u001b[39m=\u001b[39m df_credit[df_credit[\u001b[39m\"\u001b[39;49m\u001b[39mRisk\u001b[39;49m\u001b[39m\"\u001b[39;49m]\u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mgood\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mRisk\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mvalue_counts()\u001b[39m.\u001b[39mindex\u001b[39m.\u001b[39mvalues,\n\u001b[0;32m     18\u001b[0m             y \u001b[39m=\u001b[39m df_credit[df_credit[\u001b[39m\"\u001b[39m\u001b[39mRisk\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mgood\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mRisk\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mvalue_counts()\u001b[39m.\u001b[39mvalues,\n\u001b[0;32m     19\u001b[0m             name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mGood credit\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m     20\u001b[0m     )\n\u001b[0;32m     22\u001b[0m trace1 \u001b[39m=\u001b[39m go\u001b[39m.\u001b[39mBar(\n\u001b[0;32m     23\u001b[0m             x \u001b[39m=\u001b[39m df_credit[df_credit[\u001b[39m\"\u001b[39m\u001b[39mRisk\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mbad\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mRisk\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mvalue_counts()\u001b[39m.\u001b[39mindex\u001b[39m.\u001b[39mvalues,\n\u001b[0;32m     24\u001b[0m             y \u001b[39m=\u001b[39m df_credit[df_credit[\u001b[39m\"\u001b[39m\u001b[39mRisk\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mbad\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mRisk\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mvalue_counts()\u001b[39m.\u001b[39mvalues,\n\u001b[0;32m     25\u001b[0m             name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mBad credit\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m     26\u001b[0m     )\n\u001b[0;32m     28\u001b[0m data \u001b[39m=\u001b[39m [trace0, trace1]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\frame.py:3807\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3805\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   3806\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3807\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[0;32m   3808\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3809\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\indexes\\base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m-> 3804\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   3805\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   3806\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3807\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3808\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3809\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Risk'"
     ]
    }
   ],
   "source": [
    "print(\"foo\")\n",
    "#4. Some explorations:\n",
    "#   Starting by distribuition of column Age.\n",
    "#   Some Seaborn graphical\n",
    "#   Columns crossing\n",
    "\n",
    "\n",
    "# it's a library that we work with plotly\n",
    "import plotly.offline as py \n",
    "py.init_notebook_mode(connected=True) # this code, allow us to work with offline plotly version\n",
    "import plotly.graph_objs as go # it's like \"plt\" of matplot\n",
    "import plotly.tools as tls # It's useful to we get some tools of plotly\n",
    "import warnings # This library will be used to ignore some warnings\n",
    "from collections import Counter # To do counter of some features\n",
    "\n",
    "trace0 = go.Bar(\n",
    "            x = df_credit[df_credit[\"Risk\"]== 'good'][\"Risk\"].value_counts().index.values,\n",
    "            y = df_credit[df_credit[\"Risk\"]== 'good'][\"Risk\"].value_counts().values,\n",
    "            name='Good credit'\n",
    "    )\n",
    "\n",
    "trace1 = go.Bar(\n",
    "            x = df_credit[df_credit[\"Risk\"]== 'bad'][\"Risk\"].value_counts().index.values,\n",
    "            y = df_credit[df_credit[\"Risk\"]== 'bad'][\"Risk\"].value_counts().values,\n",
    "            name='Bad credit'\n",
    "    )\n",
    "\n",
    "data = [trace0, trace1]\n",
    "\n",
    "layout = go.Layout(\n",
    "    \n",
    ")\n",
    "\n",
    "layout = go.Layout(\n",
    "    yaxis=dict(\n",
    "        title='Count'\n",
    "    ),\n",
    "    xaxis=dict(\n",
    "        title='Risk Variable'\n",
    "    ),\n",
    "    title='Target variable distribution'\n",
    ")\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "\n",
    "py.iplot(fig, filename='grouped-bar')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Risk'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\indexes\\base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3801\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\_libs\\index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\_libs\\index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Risk'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df_good \u001b[39m=\u001b[39m df_credit\u001b[39m.\u001b[39mloc[df_credit[\u001b[39m\"\u001b[39;49m\u001b[39mRisk\u001b[39;49m\u001b[39m\"\u001b[39;49m] \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mgood\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mAge\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mvalues\u001b[39m.\u001b[39mtolist()\n\u001b[0;32m      2\u001b[0m df_bad \u001b[39m=\u001b[39m df_credit\u001b[39m.\u001b[39mloc[df_credit[\u001b[39m\"\u001b[39m\u001b[39mRisk\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mbad\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mAge\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mvalues\u001b[39m.\u001b[39mtolist()\n\u001b[0;32m      3\u001b[0m df_age \u001b[39m=\u001b[39m df_credit[\u001b[39m'\u001b[39m\u001b[39mAge\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mvalues\u001b[39m.\u001b[39mtolist()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\frame.py:3807\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3805\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   3806\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3807\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[0;32m   3808\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3809\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\indexes\\base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m-> 3804\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   3805\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   3806\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3807\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3808\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3809\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Risk'"
     ]
    }
   ],
   "source": [
    "df_good = df_credit.loc[df_credit[\"Risk\"] == 'good']['Age'].values.tolist()\n",
    "df_bad = df_credit.loc[df_credit[\"Risk\"] == 'bad']['Age'].values.tolist()\n",
    "df_age = df_credit['Age'].values.tolist()\n",
    "\n",
    "#First plot\n",
    "trace0 = go.Histogram(\n",
    "    x=df_good,\n",
    "    histnorm='probability',\n",
    "    name=\"Good Credit\"\n",
    ")\n",
    "#Second plot\n",
    "trace1 = go.Histogram(\n",
    "    x=df_bad,\n",
    "    histnorm='probability',\n",
    "    name=\"Bad Credit\"\n",
    ")\n",
    "#Third plot\n",
    "trace2 = go.Histogram(\n",
    "    x=df_age,\n",
    "    histnorm='probability',\n",
    "    name=\"Overall Age\"\n",
    ")\n",
    "\n",
    "#Creating the grid\n",
    "fig = tls.make_subplots(rows=2, cols=2, specs=[[{}, {}], [{'colspan': 2}, None]],\n",
    "                          subplot_titles=('Good','Bad', 'General Distribuition'))\n",
    "\n",
    "#setting the figs\n",
    "fig.append_trace(trace0, 1, 1)\n",
    "fig.append_trace(trace1, 1, 2)\n",
    "fig.append_trace(trace2, 2, 1)\n",
    "\n",
    "fig['layout'].update(showlegend=True, title='Age Distribuition', bargap=0.05)\n",
    "py.iplot(fig, filename='custom-sized-subplot-with-subplot-titles')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Risk'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\indexes\\base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3801\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\_libs\\index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\_libs\\index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Risk'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df_good \u001b[39m=\u001b[39m df_credit[df_credit[\u001b[39m\"\u001b[39;49m\u001b[39mRisk\u001b[39;49m\u001b[39m\"\u001b[39;49m] \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mgood\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m      2\u001b[0m df_bad \u001b[39m=\u001b[39m df_credit[df_credit[\u001b[39m\"\u001b[39m\u001b[39mRisk\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mbad\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m      4\u001b[0m fig, ax \u001b[39m=\u001b[39m plt\u001b[39m.\u001b[39msubplots(nrows\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m, figsize\u001b[39m=\u001b[39m(\u001b[39m12\u001b[39m,\u001b[39m8\u001b[39m))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\frame.py:3807\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3805\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   3806\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3807\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[0;32m   3808\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3809\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\indexes\\base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m-> 3804\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   3805\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   3806\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3807\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3808\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3809\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Risk'"
     ]
    }
   ],
   "source": [
    "df_good = df_credit[df_credit[\"Risk\"] == 'good']\n",
    "df_bad = df_credit[df_credit[\"Risk\"] == 'bad']\n",
    "\n",
    "fig, ax = plt.subplots(nrows=2, figsize=(12,8))\n",
    "plt.subplots_adjust(hspace = 0.4, top = 0.8)\n",
    "\n",
    "g1 = sns.distplot(df_good[\"Age\"], ax=ax[0], \n",
    "             color=\"g\")\n",
    "g1 = sns.distplot(df_bad[\"Age\"], ax=ax[0], \n",
    "             color='r')\n",
    "g1.set_title(\"Age Distribuition\", fontsize=15)\n",
    "g1.set_xlabel(\"Age\")\n",
    "g1.set_xlabel(\"Frequency\")\n",
    "\n",
    "g2 = sns.countplot(x=\"Age\",data=df_credit, \n",
    "              palette=\"hls\", ax=ax[1], \n",
    "              hue = \"Risk\")\n",
    "g2.set_title(\"Age Counting by Risk\", fontsize=15)\n",
    "g2.set_xlabel(\"Age\")\n",
    "g2.set_xlabel(\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m interval \u001b[39m=\u001b[39m (\u001b[39m18\u001b[39m, \u001b[39m25\u001b[39m, \u001b[39m35\u001b[39m, \u001b[39m60\u001b[39m, \u001b[39m120\u001b[39m)\n\u001b[0;32m      6\u001b[0m cats \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mStudent\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mYoung\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mAdult\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mSenior\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m----> 7\u001b[0m df_credit[\u001b[39m\"\u001b[39m\u001b[39mAge_cat\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mcut(df_credit\u001b[39m.\u001b[39mAge, interval, labels\u001b[39m=\u001b[39mcats)\n\u001b[0;32m     10\u001b[0m df_good \u001b[39m=\u001b[39m df_credit[df_credit[\u001b[39m\"\u001b[39m\u001b[39mRisk\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mgood\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m     11\u001b[0m df_bad \u001b[39m=\u001b[39m df_credit[df_credit[\u001b[39m\"\u001b[39m\u001b[39mRisk\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mbad\u001b[39m\u001b[39m'\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# Creating an categorical variable to handle with the Age variable\n",
    "\n",
    "#Let's look the Credit Amount column\n",
    "interval = (18, 25, 35, 60, 120)\n",
    "\n",
    "cats = ['Student', 'Young', 'Adult', 'Senior']\n",
    "df_credit[\"Age_cat\"] = pd.cut(df_credit.Age, interval, labels=cats)\n",
    "\n",
    "\n",
    "df_good = df_credit[df_credit[\"Risk\"] == 'good']\n",
    "df_bad = df_credit[df_credit[\"Risk\"] == 'bad']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace0 = go.Box(\n",
    "    y=df_good[\"Credit amount\"],\n",
    "    x=df_good[\"Age_cat\"],\n",
    "    name='Good credit',\n",
    "    marker=dict(\n",
    "        color='#3D9970'\n",
    "    )\n",
    ")\n",
    "\n",
    "trace1 = go.Box(\n",
    "    y=df_bad['Credit amount'],\n",
    "    x=df_bad['Age_cat'],\n",
    "    name='Bad credit',\n",
    "    marker=dict(\n",
    "        color='#FF4136'\n",
    "    )\n",
    ")\n",
    "    \n",
    "data = [trace0, trace1]\n",
    "\n",
    "layout = go.Layout(\n",
    "    yaxis=dict(\n",
    "        title='Credit Amount (US Dollar)',\n",
    "        zeroline=False\n",
    "    ),\n",
    "    xaxis=dict(\n",
    "        title='Age Categorical'\n",
    "    ),\n",
    "    boxmode='group'\n",
    ")\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "\n",
    "py.iplot(fig, filename='box-age-cat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I will now Look the distribuition of Housing own and rent by Risk\n",
    "\n",
    "#First plot\n",
    "trace0 = go.Bar(\n",
    "    x = df_credit[df_credit[\"Risk\"]== 'good'][\"Housing\"].value_counts().index.values,\n",
    "    y = df_credit[df_credit[\"Risk\"]== 'good'][\"Housing\"].value_counts().values,\n",
    "    name='Good credit'\n",
    ")\n",
    "\n",
    "#Second plot\n",
    "trace1 = go.Bar(\n",
    "    x = df_credit[df_credit[\"Risk\"]== 'bad'][\"Housing\"].value_counts().index.values,\n",
    "    y = df_credit[df_credit[\"Risk\"]== 'bad'][\"Housing\"].value_counts().values,\n",
    "    name=\"Bad Credit\"\n",
    ")\n",
    "\n",
    "data = [trace0, trace1]\n",
    "\n",
    "layout = go.Layout(\n",
    "    title='Housing Distribuition'\n",
    ")\n",
    "\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "\n",
    "py.iplot(fig, filename='Housing-Grouped')\n",
    "\n",
    "#we can see that the own and good risk have a high correlation\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribuition of Credit Amount by Housing\n",
    "\n",
    "fig = {\n",
    "    \"data\": [\n",
    "        {\n",
    "            \"type\": 'violin',\n",
    "            \"x\": df_good['Housing'],\n",
    "            \"y\": df_good['Credit amount'],\n",
    "            \"legendgroup\": 'Good Credit',\n",
    "            \"scalegroup\": 'No',\n",
    "            \"name\": 'Good Credit',\n",
    "            \"side\": 'negative',\n",
    "            \"box\": {\n",
    "                \"visible\": True\n",
    "            },\n",
    "            \"meanline\": {\n",
    "                \"visible\": True\n",
    "            },\n",
    "            \"line\": {\n",
    "                \"color\": 'blue'\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"type\": 'violin',\n",
    "            \"x\": df_bad['Housing'],\n",
    "            \"y\": df_bad['Credit amount'],\n",
    "            \"legendgroup\": 'Bad Credit',\n",
    "            \"scalegroup\": 'No',\n",
    "            \"name\": 'Bad Credit',\n",
    "            \"side\": 'positive',\n",
    "            \"box\": {\n",
    "                \"visible\": True\n",
    "            },\n",
    "            \"meanline\": {\n",
    "                \"visible\": True\n",
    "            },\n",
    "            \"line\": {\n",
    "                \"color\": 'green'\n",
    "            }\n",
    "        }\n",
    "    ],\n",
    "    \"layout\" : {\n",
    "        \"yaxis\": {\n",
    "            \"zeroline\": False,\n",
    "        },\n",
    "        \"violingap\": 0,\n",
    "        \"violinmode\": \"overlay\"\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "py.iplot(fig, filename = 'violin/split', validate = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking the diference by Sex\n",
    "\n",
    "#First plot\n",
    "trace0 = go.Bar(\n",
    "    x = df_credit[df_credit[\"Risk\"]== 'good'][\"Sex\"].value_counts().index.values,\n",
    "    y = df_credit[df_credit[\"Risk\"]== 'good'][\"Sex\"].value_counts().values,\n",
    "    name='Good credit'\n",
    ")\n",
    "\n",
    "#First plot 2\n",
    "trace1 = go.Bar(\n",
    "    x = df_credit[df_credit[\"Risk\"]== 'bad'][\"Sex\"].value_counts().index.values,\n",
    "    y = df_credit[df_credit[\"Risk\"]== 'bad'][\"Sex\"].value_counts().values,\n",
    "    name=\"Bad Credit\"\n",
    ")\n",
    "\n",
    "#Second plot\n",
    "trace2 = go.Box(\n",
    "    x = df_credit[df_credit[\"Risk\"]== 'good'][\"Sex\"],\n",
    "    y = df_credit[df_credit[\"Risk\"]== 'good'][\"Credit amount\"],\n",
    "    name=trace0.name\n",
    ")\n",
    "\n",
    "#Second plot 2\n",
    "trace3 = go.Box(\n",
    "    x = df_credit[df_credit[\"Risk\"]== 'bad'][\"Sex\"],\n",
    "    y = df_credit[df_credit[\"Risk\"]== 'bad'][\"Credit amount\"],\n",
    "    name=trace1.name\n",
    ")\n",
    "\n",
    "data = [trace0, trace1, trace2,trace3]\n",
    "\n",
    "\n",
    "fig = tls.make_subplots(rows=1, cols=2, \n",
    "                        subplot_titles=('Sex Count', 'Credit Amount by Sex'))\n",
    "\n",
    "fig.append_trace(trace0, 1, 1)\n",
    "fig.append_trace(trace1, 1, 1)\n",
    "fig.append_trace(trace2, 1, 2)\n",
    "fig.append_trace(trace3, 1, 2)\n",
    "\n",
    "fig['layout'].update(height=400, width=800, title='Sex Distribuition', boxmode='group')\n",
    "py.iplot(fig, filename='sex-subplot')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I will create categories of Age and look the distribuition of Credit Amount by Risk...\n",
    "#I will do some explorations through the Job\n",
    "\n",
    "# Distribuition\n",
    "# Crossed by Credit amount\n",
    "# Crossed by Age\n",
    "\n",
    "#First plot\n",
    "trace0 = go.Bar(\n",
    "    x = df_credit[df_credit[\"Risk\"]== 'good'][\"Job\"].value_counts().index.values,\n",
    "    y = df_credit[df_credit[\"Risk\"]== 'good'][\"Job\"].value_counts().values,\n",
    "    name='Good credit Distribuition'\n",
    ")\n",
    "\n",
    "#Second plot\n",
    "trace1 = go.Bar(\n",
    "    x = df_credit[df_credit[\"Risk\"]== 'bad'][\"Job\"].value_counts().index.values,\n",
    "    y = df_credit[df_credit[\"Risk\"]== 'bad'][\"Job\"].value_counts().values,\n",
    "    name=\"Bad Credit Distribuition\"\n",
    ")\n",
    "\n",
    "data = [trace0, trace1]\n",
    "\n",
    "layout = go.Layout(\n",
    "    title='Job Distribuition'\n",
    ")\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "\n",
    "py.iplot(fig, filename='grouped-bar')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace0 = go.Box(\n",
    "    x=df_good[\"Job\"],\n",
    "    y=df_good[\"Credit amount\"],\n",
    "    name='Good credit'\n",
    ")\n",
    "\n",
    "trace1 = go.Box(\n",
    "    x=df_bad['Job'],\n",
    "    y=df_bad['Credit amount'],\n",
    "    name='Bad credit'\n",
    ")\n",
    "    \n",
    "data = [trace0, trace1]\n",
    "\n",
    "layout = go.Layout(\n",
    "    yaxis=dict(\n",
    "        title='Credit Amount distribuition by Job'\n",
    "    ),\n",
    "    boxmode='group'\n",
    ")\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "\n",
    "py.iplot(fig, filename='box-age-cat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = {\n",
    "    \"data\": [\n",
    "        {\n",
    "            \"type\": 'violin',\n",
    "            \"x\": df_good['Job'],\n",
    "            \"y\": df_good['Age'],\n",
    "            \"legendgroup\": 'Good Credit',\n",
    "            \"scalegroup\": 'No',\n",
    "            \"name\": 'Good Credit',\n",
    "            \"side\": 'negative',\n",
    "            \"box\": {\n",
    "                \"visible\": True\n",
    "            },\n",
    "            \"meanline\": {\n",
    "                \"visible\": True\n",
    "            },\n",
    "            \"line\": {\n",
    "                \"color\": 'blue'\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"type\": 'violin',\n",
    "            \"x\": df_bad['Job'],\n",
    "            \"y\": df_bad['Age'],\n",
    "            \"legendgroup\": 'Bad Credit',\n",
    "            \"scalegroup\": 'No',\n",
    "            \"name\": 'Bad Credit',\n",
    "            \"side\": 'positive',\n",
    "            \"box\": {\n",
    "                \"visible\": True\n",
    "            },\n",
    "            \"meanline\": {\n",
    "                \"visible\": True\n",
    "            },\n",
    "            \"line\": {\n",
    "                \"color\": 'green'\n",
    "            }\n",
    "        }\n",
    "    ],\n",
    "    \"layout\" : {\n",
    "        \"yaxis\": {\n",
    "            \"zeroline\": False,\n",
    "        },\n",
    "        \"violingap\": 0,\n",
    "        \"violinmode\": \"overlay\"\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "py.iplot(fig, filename = 'Age-Housing', validate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,12), nrows=2)\n",
    "\n",
    "g1 = sns.boxplot(x=\"Job\", y=\"Credit amount\", data=df_credit, \n",
    "            palette=\"hls\", ax=ax[0], hue=\"Risk\")\n",
    "g1.set_title(\"Credit Amount by Job\", fontsize=15)\n",
    "g1.set_xlabel(\"Job Reference\", fontsize=12)\n",
    "g1.set_ylabel(\"Credit Amount\", fontsize=12)\n",
    "\n",
    "g2 = sns.violinplot(x=\"Job\", y=\"Age\", data=df_credit, ax=ax[1],  \n",
    "               hue=\"Risk\", split=True, palette=\"hls\")\n",
    "g2.set_title(\"Job Type reference x Age\", fontsize=15)\n",
    "g2.set_xlabel(\"Job Reference\", fontsize=12)\n",
    "g2.set_ylabel(\"Age\", fontsize=12)\n",
    "\n",
    "plt.subplots_adjust(hspace = 0.4,top = 0.9)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking the distribuition of Credit Amont\n",
    "\n",
    "import plotly.figure_factory as ff\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Add histogram data\n",
    "x1 = np.log(df_good['Credit amount']) \n",
    "x2 = np.log(df_bad[\"Credit amount\"])\n",
    "\n",
    "# Group data together\n",
    "hist_data = [x1, x2]\n",
    "\n",
    "group_labels = ['Good Credit', 'Bad Credit']\n",
    "\n",
    "# Create distplot with custom bin_size\n",
    "fig = ff.create_distplot(hist_data, group_labels, bin_size=.2)\n",
    "\n",
    "# Plot!\n",
    "py.iplot(fig, filename='Distplot with Multiple Datasets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ploting the good and bad dataframes in distplot\n",
    "plt.figure(figsize = (8,5))\n",
    "\n",
    "g= sns.distplot(df_good['Credit amount'], color='r')\n",
    "g = sns.distplot(df_bad[\"Credit amount\"], color='g')\n",
    "g.set_title(\"Credit Amount Frequency distribuition\", fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Distruibution of Saving accounts by Risk\n",
    "\n",
    "from plotly import tools\n",
    "import numpy as np\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "count_good = go.Bar(\n",
    "    x = df_good[\"Saving accounts\"].value_counts().index.values,\n",
    "    y = df_good[\"Saving accounts\"].value_counts().values,\n",
    "    name='Good credit'\n",
    ")\n",
    "count_bad = go.Bar(\n",
    "    x = df_bad[\"Saving accounts\"].value_counts().index.values,\n",
    "    y = df_bad[\"Saving accounts\"].value_counts().values,\n",
    "    name='Bad credit'\n",
    ")\n",
    "\n",
    "\n",
    "box_1 = go.Box(\n",
    "    x=df_good[\"Saving accounts\"],\n",
    "    y=df_good[\"Credit amount\"],\n",
    "    name='Good credit'\n",
    ")\n",
    "box_2 = go.Box(\n",
    "    x=df_bad[\"Saving accounts\"],\n",
    "    y=df_bad[\"Credit amount\"],\n",
    "    name='Bad credit'\n",
    ")\n",
    "\n",
    "scat_1 = go.Box(\n",
    "    x=df_good[\"Saving accounts\"],\n",
    "    y=df_good[\"Age\"],\n",
    "    name='Good credit'\n",
    ")\n",
    "scat_2 = go.Box(\n",
    "    x=df_bad[\"Saving accounts\"],\n",
    "    y=df_bad[\"Age\"],\n",
    "    name='Bad credit'\n",
    ")\n",
    "\n",
    "data = [scat_1, scat_2, box_1, box_2, count_good, count_bad]\n",
    "\n",
    "fig = tools.make_subplots(rows=2, cols=2, specs=[[{}, {}], [{'colspan': 2}, None]],\n",
    "                          subplot_titles=('Count Saving Accounts','Credit Amount by Savings Acc', \n",
    "                                          'Age by Saving accounts'))\n",
    "\n",
    "fig.append_trace(count_good, 1, 1)\n",
    "fig.append_trace(count_bad, 1, 1)\n",
    "\n",
    "fig.append_trace(box_2, 1, 2)\n",
    "fig.append_trace(box_1, 1, 2)\n",
    "\n",
    "fig.append_trace(scat_1, 2, 1)\n",
    "fig.append_trace(scat_2, 2, 1)\n",
    "\n",
    "\n",
    "\n",
    "fig['layout'].update(height=700, width=800, title='Saving Accounts Exploration', boxmode='group')\n",
    "\n",
    "py.iplot(fig, filename='combined-savings')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How can I better configure the legends? I am trying to substitute the graph below, so how can I use the violinplot on subplots of plotly?\n",
    "\n",
    "print(\"Description of Distribuition Saving accounts by Risk:  \")\n",
    "print(pd.crosstab(df_credit[\"Saving accounts\"],df_credit.Risk))\n",
    "\n",
    "fig, ax = plt.subplots(3,1, figsize=(12,12))\n",
    "g = sns.countplot(x=\"Saving accounts\", data=df_credit, palette=\"hls\", \n",
    "              ax=ax[0],hue=\"Risk\")\n",
    "g.set_title(\"Saving Accounts Count\", fontsize=15)\n",
    "g.set_xlabel(\"Saving Accounts type\", fontsize=12)\n",
    "g.set_ylabel(\"Count\", fontsize=12)\n",
    "\n",
    "g1 = sns.violinplot(x=\"Saving accounts\", y=\"Job\", data=df_credit, palette=\"hls\", \n",
    "               hue = \"Risk\", ax=ax[1],split=True)\n",
    "g1.set_title(\"Saving Accounts by Job\", fontsize=15)\n",
    "g1.set_xlabel(\"Savings Accounts type\", fontsize=12)\n",
    "g1.set_ylabel(\"Job\", fontsize=12)\n",
    "\n",
    "g = sns.boxplot(x=\"Saving accounts\", y=\"Credit amount\", data=df_credit, ax=ax[2],\n",
    "            hue = \"Risk\",palette=\"hls\")\n",
    "g2.set_title(\"Saving Accounts by Credit Amount\", fontsize=15)\n",
    "g2.set_xlabel(\"Savings Accounts type\", fontsize=12)\n",
    "g2.set_ylabel(\"Credit Amount(US)\", fontsize=12)\n",
    "\n",
    "plt.subplots_adjust(hspace = 0.4,top = 0.9)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Values describe: \")\n",
    "print(pd.crosstab(df_credit.Purpose, df_credit.Risk))\n",
    "\n",
    "plt.figure(figsize = (14,12))\n",
    "\n",
    "plt.subplot(221)\n",
    "g = sns.countplot(x=\"Purpose\", data=df_credit, \n",
    "              palette=\"hls\", hue = \"Risk\")\n",
    "g.set_xticklabels(g.get_xticklabels(),rotation=45)\n",
    "g.set_xlabel(\"\", fontsize=12)\n",
    "g.set_ylabel(\"Count\", fontsize=12)\n",
    "g.set_title(\"Purposes Count\", fontsize=20)\n",
    "\n",
    "plt.subplot(222)\n",
    "g1 = sns.violinplot(x=\"Purpose\", y=\"Age\", data=df_credit, \n",
    "                    palette=\"hls\", hue = \"Risk\",split=True)\n",
    "g1.set_xticklabels(g1.get_xticklabels(),rotation=45)\n",
    "g1.set_xlabel(\"\", fontsize=12)\n",
    "g1.set_ylabel(\"Count\", fontsize=12)\n",
    "g1.set_title(\"Purposes by Age\", fontsize=20)\n",
    "\n",
    "plt.subplot(212)\n",
    "g2 = sns.boxplot(x=\"Purpose\", y=\"Credit amount\", data=df_credit, \n",
    "               palette=\"hls\", hue = \"Risk\")\n",
    "g2.set_xlabel(\"Purposes\", fontsize=12)\n",
    "g2.set_ylabel(\"Credit Amount\", fontsize=12)\n",
    "g2.set_title(\"Credit Amount distribuition by Purposes\", fontsize=20)\n",
    "\n",
    "plt.subplots_adjust(hspace = 0.6, top = 0.8)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duration of the loans distribuition and density\n",
    "\n",
    "plt.figure(figsize = (12,14))\n",
    "\n",
    "g= plt.subplot(311)\n",
    "g = sns.countplot(x=\"Duration\", data=df_credit, \n",
    "              palette=\"hls\",  hue = \"Risk\")\n",
    "g.set_xlabel(\"Duration Distribuition\", fontsize=12)\n",
    "g.set_ylabel(\"Count\", fontsize=12)\n",
    "g.set_title(\"Duration Count\", fontsize=20)\n",
    "\n",
    "g1 = plt.subplot(312)\n",
    "g1 = sns.pointplot(x=\"Duration\", y =\"Credit amount\",data=df_credit,\n",
    "                   hue=\"Risk\", palette=\"hls\")\n",
    "g1.set_xlabel(\"Duration\", fontsize=12)\n",
    "g1.set_ylabel(\"Credit Amount(US)\", fontsize=12)\n",
    "g1.set_title(\"Credit Amount distribuition by Duration\", fontsize=20)\n",
    "\n",
    "g2 = plt.subplot(313)\n",
    "g2 = sns.distplot(df_good[\"Duration\"], color='g')\n",
    "g2 = sns.distplot(df_bad[\"Duration\"], color='r')\n",
    "g2.set_xlabel(\"Duration\", fontsize=12)\n",
    "g2.set_ylabel(\"Frequency\", fontsize=12)\n",
    "g2.set_title(\"Duration Frequency x good and bad Credit\", fontsize=20)\n",
    "\n",
    "plt.subplots_adjust(wspace = 0.4, hspace = 0.4,top = 0.9)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking Account variable\n",
    "\n",
    "#First plot\n",
    "trace0 = go.Bar(\n",
    "    x = df_credit[df_credit[\"Risk\"]== 'good'][\"Checking account\"].value_counts().index.values,\n",
    "    y = df_credit[df_credit[\"Risk\"]== 'good'][\"Checking account\"].value_counts().values,\n",
    "    name='Good credit Distribuition' \n",
    "    \n",
    ")\n",
    "\n",
    "#Second plot\n",
    "trace1 = go.Bar(\n",
    "    x = df_credit[df_credit[\"Risk\"]== 'bad'][\"Checking account\"].value_counts().index.values,\n",
    "    y = df_credit[df_credit[\"Risk\"]== 'bad'][\"Checking account\"].value_counts().values,\n",
    "    name=\"Bad Credit Distribuition\"\n",
    ")\n",
    "\n",
    "data = [trace0, trace1]\n",
    "\n",
    "layout = go.Layout(\n",
    "    title='Checking accounts Distribuition',\n",
    "    xaxis=dict(title='Checking accounts name'),\n",
    "    yaxis=dict(title='Count'),\n",
    "    barmode='group'\n",
    ")\n",
    "\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "\n",
    "py.iplot(fig, filename = 'Age-ba', validate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, we will verify the values through Checking Accounts\n",
    "\n",
    "df_good = df_credit[df_credit[\"Risk\"] == 'good']\n",
    "df_bad = df_credit[df_credit[\"Risk\"] == 'bad']\n",
    "\n",
    "trace0 = go.Box(\n",
    "    y=df_good[\"Credit amount\"],\n",
    "    x=df_good[\"Checking account\"],\n",
    "    name='Good credit',\n",
    "    marker=dict(\n",
    "        color='#3D9970'\n",
    "    )\n",
    ")\n",
    "\n",
    "trace1 = go.Box(\n",
    "    y=df_bad['Credit amount'],\n",
    "    x=df_bad['Checking account'],\n",
    "    name='Bad credit',\n",
    "    marker=dict(\n",
    "        color='#FF4136'\n",
    "    )\n",
    ")\n",
    "    \n",
    "data = [trace0, trace1]\n",
    "\n",
    "layout = go.Layout(\n",
    "    yaxis=dict(\n",
    "        title='Cheking distribuition'\n",
    "    ),\n",
    "    boxmode='group'\n",
    ")\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "\n",
    "py.iplot(fig, filename='box-age-cat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The old plot that I am trying to substitute with interactive plots\n",
    "\n",
    "print(\"Total values of the most missing variable: \")\n",
    "print(df_credit.groupby(\"Checking account\")[\"Checking account\"].count())\n",
    "\n",
    "plt.figure(figsize = (12,10))\n",
    "\n",
    "g = plt.subplot(221)\n",
    "g = sns.countplot(x=\"Checking account\", data=df_credit, \n",
    "              palette=\"hls\", hue=\"Risk\")\n",
    "g.set_xlabel(\"Checking Account\", fontsize=12)\n",
    "g.set_ylabel(\"Count\", fontsize=12)\n",
    "g.set_title(\"Checking Account Counting by Risk\", fontsize=20)\n",
    "\n",
    "g1 = plt.subplot(222)\n",
    "g1 = sns.violinplot(x=\"Checking account\", y=\"Age\", data=df_credit, palette=\"hls\", hue = \"Risk\",split=True)\n",
    "g1.set_xlabel(\"Checking Account\", fontsize=12)\n",
    "g1.set_ylabel(\"Age\", fontsize=12)\n",
    "g1.set_title(\"Age by Checking Account\", fontsize=20)\n",
    "\n",
    "g2 = plt.subplot(212)\n",
    "g2 = sns.boxplot(x=\"Checking account\",y=\"Credit amount\", data=df_credit,hue='Risk',palette=\"hls\")\n",
    "g2.set_xlabel(\"Checking Account\", fontsize=12)\n",
    "g2.set_ylabel(\"Credit Amount(US)\", fontsize=12)\n",
    "g2.set_title(\"Credit Amount by Cheking Account\", fontsize=20)\n",
    "\n",
    "plt.subplots_adjust(wspace = 0.2, hspace = 0.3, top = 0.9)\n",
    "\n",
    "plt.show()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crosstab session and anothers to explore our data by another metrics a little deep\n",
    "\n",
    "print(pd.crosstab(df_credit.Sex, df_credit.Job))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,6))\n",
    "\n",
    "g = sns.violinplot(x=\"Housing\",y=\"Job\",data=df_credit,\n",
    "                   hue=\"Risk\", palette=\"hls\",split=True)\n",
    "g.set_xlabel(\"Housing\", fontsize=12)\n",
    "g.set_ylabel(\"Job\", fontsize=12)\n",
    "g.set_title(\"Housing x Job - Dist\", fontsize=20)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.crosstab(df_credit[\"Checking account\"],df_credit.Sex))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_int = [\"Purpose\", 'Sex']\n",
    "cm = sns.light_palette(\"green\", as_cmap=True)\n",
    "pd.crosstab(df_credit[date_int[0]], df_credit[date_int[1]]).style.background_gradient(cmap = cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_int = [\"Purpose\", 'Sex']\n",
    "cm = sns.light_palette(\"green\", as_cmap=True)\n",
    "pd.crosstab(df_credit[date_int[0]], df_credit[date_int[1]]).style.background_gradient(cmap = cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking the total of values in each categorical feature\n",
    "\n",
    "print(\"Purpose : \",df_credit.Purpose.unique())\n",
    "print(\"Sex : \",df_credit.Sex.unique())\n",
    "print(\"Housing : \",df_credit.Housing.unique())\n",
    "print(\"Saving accounts : \",df_credit['Saving accounts'].unique())\n",
    "print(\"Risk : \",df_credit['Risk'].unique())\n",
    "print(\"Checking account : \",df_credit['Checking account'].unique())\n",
    "print(\"Aget_cat : \",df_credit['Age_cat'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's do some feature engineering on this values and create variable Dummies of the values\n",
    "\n",
    "def one_hot_encoder(df, nan_as_category = False):\n",
    "    original_columns = list(df.columns)\n",
    "    categorical_columns = [col for col in df.columns if df[col].dtype == 'object']\n",
    "    df = pd.get_dummies(df, columns= categorical_columns, dummy_na= nan_as_category, drop_first=True)\n",
    "    new_columns = [c for c in df.columns if c not in original_columns]\n",
    "    return df, new_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming the data into Dummy variables\n",
    "\n",
    "df_credit['Saving accounts'] = df_credit['Saving accounts'].fillna('no_inf')\n",
    "df_credit['Checking account'] = df_credit['Checking account'].fillna('no_inf')\n",
    "\n",
    "#Purpose to Dummies Variable\n",
    "df_credit = df_credit.merge(pd.get_dummies(df_credit.Purpose, drop_first=True, prefix='Purpose'), left_index=True, right_index=True)\n",
    "#Sex feature in dummies\n",
    "df_credit = df_credit.merge(pd.get_dummies(df_credit.Sex, drop_first=True, prefix='Sex'), left_index=True, right_index=True)\n",
    "# Housing get dummies\n",
    "df_credit = df_credit.merge(pd.get_dummies(df_credit.Housing, drop_first=True, prefix='Housing'), left_index=True, right_index=True)\n",
    "# Housing get Saving Accounts\n",
    "df_credit = df_credit.merge(pd.get_dummies(df_credit[\"Saving accounts\"], drop_first=True, prefix='Savings'), left_index=True, right_index=True)\n",
    "# Housing get Risk\n",
    "df_credit = df_credit.merge(pd.get_dummies(df_credit.Risk, prefix='Risk'), left_index=True, right_index=True)\n",
    "# Housing get Checking Account\n",
    "df_credit = df_credit.merge(pd.get_dummies(df_credit[\"Checking account\"], drop_first=True, prefix='Check'), left_index=True, right_index=True)\n",
    "# Housing get Age categorical\n",
    "df_credit = df_credit.merge(pd.get_dummies(df_credit[\"Age_cat\"], drop_first=True, prefix='Age_cat'), left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deleting the old features\n",
    "\n",
    "#Excluding the missing columns\n",
    "del df_credit[\"Saving accounts\"]\n",
    "del df_credit[\"Checking account\"]\n",
    "del df_credit[\"Purpose\"]\n",
    "del df_credit[\"Sex\"]\n",
    "del df_credit[\"Housing\"]\n",
    "del df_credit[\"Age_cat\"]\n",
    "del df_credit[\"Risk\"]\n",
    "del df_credit['Risk_good']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.- Correlation\n",
    "# Looking the data correlation\n",
    "\n",
    "plt.figure(figsize=(14,12))\n",
    "sns.heatmap(df_credit.astype(float).corr(),linewidths=0.1,vmax=1.0, \n",
    "            square=True,  linecolor='white', annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6 .- Pre Processing\n",
    "\n",
    "# Importing ML librarys\n",
    "# Setting X and y variables to the prediction\n",
    "# Splitting Data\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score # to split the data\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, fbeta_score #To evaluate our model\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Algorithmns models to be compared\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "df_credit['Credit amount'] = np.log(df_credit['Credit amount'])\n",
    "\n",
    "#Creating the X and y variables\n",
    "X = df_credit.drop('Risk_bad', 1).values\n",
    "y = df_credit[\"Risk_bad\"].values\n",
    "\n",
    "# Spliting X and y into train and test version\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to feed the random state\n",
    "seed = 7\n",
    "\n",
    "# prepare models\n",
    "models = []\n",
    "models.append(('LR', LogisticRegression()))\n",
    "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('CART', DecisionTreeClassifier()))\n",
    "models.append(('NB', GaussianNB()))\n",
    "models.append(('RF', RandomForestClassifier()))\n",
    "models.append(('SVM', SVC(gamma='auto')))\n",
    "models.append(('XGB', XGBClassifier()))\n",
    "\n",
    "# evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "scoring = 'recall'\n",
    "\n",
    "for name, model in models:\n",
    "        kfold = KFold(n_splits=10, random_state=seed)\n",
    "        cv_results = cross_val_score(model, X_train, y_train, cv=kfold, scoring=scoring)\n",
    "        results.append(cv_results)\n",
    "        names.append(name)\n",
    "        msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "        print(msg)\n",
    "        \n",
    "# boxplot algorithm comparison\n",
    "fig = plt.figure(figsize=(11,6))\n",
    "fig.suptitle('Algorithm Comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# to feed the random state\n",
    "seed = 7\n",
    "\n",
    "# prepare models\n",
    "models = []\n",
    "models.append(('LR', LogisticRegression()))\n",
    "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('CART', DecisionTreeClassifier()))\n",
    "models.append(('NB', GaussianNB()))\n",
    "models.append(('RF', RandomForestClassifier()))\n",
    "models.append(('SVM', SVC(gamma='auto')))\n",
    "models.append(('XGB', XGBClassifier()))\n",
    "\n",
    "# evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "scoring = 'recall'\n",
    "\n",
    "for name, model in models:\n",
    "        kfold = KFold(n_splits=10, random_state=seed)\n",
    "        cv_results = cross_val_score(model, X_train, y_train, cv=kfold, scoring=scoring)\n",
    "        results.append(cv_results)\n",
    "        names.append(name)\n",
    "        msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "        print(msg)\n",
    "        \n",
    "# boxplot algorithm comparison\n",
    "fig = plt.figure(figsize=(11,6))\n",
    "fig.suptitle('Algorithm Comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7.- Models\n",
    "\n",
    "# Using Random Forest to predictict the credit score\n",
    "# Some of Validation Parameters\n",
    "\n",
    "#Seting the Hyper Parameters\n",
    "param_grid = {\"max_depth\": [3,5, 7, 10,None],\n",
    "              \"n_estimators\":[3,5,10,25,50,150],\n",
    "              \"max_features\": [4,7,15,20]}\n",
    "\n",
    "#Creating the classifier\n",
    "model = RandomForestClassifier(random_state=2)\n",
    "\n",
    "grid_search = GridSearchCV(model, param_grid=param_grid, cv=5, scoring='recall', verbose=4)\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid_search.best_score_)\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(max_depth=None, max_features=10, n_estimators=15, random_state=2)\n",
    "\n",
    "#trainning with the best params\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing the model \n",
    "#Predicting using our  model\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "# Verificaar os resultados obtidos\n",
    "print(accuracy_score(y_test,y_pred))\n",
    "print(\"\\n\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"\\n\")\n",
    "print(fbeta_score(y_test, y_pred, beta=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7.2 Model 2\n",
    "\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "# Criando o classificador logreg\n",
    "GNB = GaussianNB()\n",
    "\n",
    "# Fitting with train data\n",
    "model = GNB.fit(X_train, y_train)\n",
    "\n",
    "# Printing the Training Score\n",
    "print(\"Training score data: \")\n",
    "print(model.score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(accuracy_score(y_test,y_pred))\n",
    "print(\"\\n\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"\\n\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's verify the ROC curve\n",
    "\n",
    "#Predicting proba\n",
    "y_pred_prob = model.predict_proba(X_test)[:,1]\n",
    "\n",
    "# Generate ROC curve values: fpr, tpr, thresholds\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SelectKBest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = []\n",
    "features.append(('pca', PCA(n_components=2)))\n",
    "features.append(('select_best', SelectKBest(k=6)))\n",
    "feature_union = FeatureUnion(features)\n",
    "# create pipeline\n",
    "estimators = []\n",
    "estimators.append(('feature_union', feature_union))\n",
    "estimators.append(('logistic', GaussianNB()))\n",
    "model = Pipeline(estimators)\n",
    "# evaluate pipeline\n",
    "seed = 7\n",
    "kfold = KFold(n_splits=10, random_state=seed)\n",
    "results = cross_val_score(model, X_train, y_train, cv=kfold)\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(accuracy_score(y_test,y_pred))\n",
    "print(\"\\n\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"\\n\")\n",
    "print(fbeta_score(y_test, y_pred, beta=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing a pipeline of models\n",
    "\n",
    "#Seting the Hyper Parameters\n",
    "param_test1 = {\n",
    " 'max_depth':[3,5,6,10],\n",
    " 'min_child_weight':[3,5,10],\n",
    " 'gamma':[0.0, 0.1, 0.2, 0.3, 0.4],\n",
    "# 'reg_alpha':[1e-5, 1e-2, 0.1, 1, 10],\n",
    " 'subsample':[i/100.0 for i in range(75,90,5)],\n",
    " 'colsample_bytree':[i/100.0 for i in range(75,90,5)]\n",
    "}\n",
    "\n",
    "#Creating the classifier\n",
    "model_xg = XGBClassifier(random_state=2)\n",
    "\n",
    "grid_search = GridSearchCV(model_xg, param_grid=param_test1, cv=5, scoring='recall')\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_score_\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = grid_search.predict(X_test)\n",
    "\n",
    "# Verificaar os resultados obtidos\n",
    "print(accuracy_score(y_test,y_pred))\n",
    "print(\"\\n\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
